{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# technical question and answer for code comparison\n",
    "# 1.  Creating a gradio platform where user can ask questions regarding code, and get answers. Now behind the scene:\n",
    "#     a.  Question is answered by 2 different LLM models\n",
    "#     b.  The answers are compared by a 3rd one and given a majority score for the best answer. Taking the best points from both these answers generates a final answer. \n",
    "#     c.  The final answer is given to the user, along with a smiley image that motivates the user to keep asking questions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bfe98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdc5d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AIzaSyCv\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "gemini_via_openai_client = OpenAI(\n",
    "        api_key=google_api_key, \n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6424c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_ollama = \"You are a coding tutor. Your job is to get the code and analyse \\\n",
    "what is happening in the code. You gently encourage the user to think about the code \\\n",
    "    1. You can ask clarifying questions to understand the level of the user \\\n",
    "    2. You should always be a good cop tutor. i.e Always be cheerful and not discourage learning \\\n",
    "    3. You can ask the user to explain the code in their own words \\\n",
    "    4. You should not go deeper into explaination of the code if the user does not ask for it\"\n",
    "  \n",
    "system_message_chatgpt = \"You are a coding tutor. Your job is to get the code and analyse \\\n",
    "what is happening in the code. You are quite strict towards the user to think about the code \\\n",
    "    1. You can ask clarifying questions to understand the level of the user \\\n",
    "    2. You should always be a bad cop tutor. i.e Not be cheerful, and be a bit condescending. \\\n",
    "    3. You can ask the user to explain the code in their own words \\\n",
    "    4. You are the best python tutor ever. You need to explain everything in detail to the user\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc13b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_gemini = \"You are the head coding tutor. Your job is to evaluate the 2 answers given \\\n",
    "    to you by the other tutors. Their names are: Alpha and Bravo. You need to evaluate the answers \\\n",
    "    Important!: Please note: User should not know that you are evaluating answers! Your evaluation category is as follows: \\\n",
    "    1. You will be provided by the question of the user \\\n",
    "    2. You will be provided by the answers of the 2 tutors \\\n",
    "    3. You have to be a fair evaluator of both the answers. You also need to give out a score \\\n",
    "    to evaluate the answers. The score categories are: {`answer quality`, `conciseness`, `relevance to the question`}. \\\n",
    "    You need to send the scores in the dictionary format as mentioned \\\n",
    "    4. Finally, you generate a final response to the user with an answer using the best of both the answers provided by the tutors \\\n",
    "    5. You also need to send a smiley image to the user to motivate them to keep asking questions \\\n",
    "    6. You should be a neutral evaluator of the answers provided by the tutors \\\n",
    "    7. You should only answer coding related questions. If the response from the other tutors is not code related, then ask the User to enter their programming related question\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f5f3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(message, gpt_history):\n",
    "    name = \"alpha\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message_chatgpt}] + gpt_history + [{\"role\": \"user\", \"content\": message}]    \n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d63754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama(message, ollama_history):\n",
    "    name = \"bravo\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message_ollama}] + ollama_history + [{\"role\": \"user\", \"content\": message}]    \n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content , name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7abd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f29631da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):   \n",
    "    \n",
    "    gpt_history = []\n",
    "    ollama_history = []\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message_gemini}]  \n",
    "    gpt_response, gpt = call_gpt(message, gpt_history)\n",
    "    ollama_response, ollama = call_ollama(message, ollama_history) \n",
    "    gpt_history.append({\"role\": \"user\", \"content\": message}) \n",
    "    ollama_history.append({\"role\": \"user\", \"content\": message})\n",
    "    composed_response = f\"Alpha: {gpt_response} \\n Bravo: {ollama_response}\" \n",
    "    print(composed_response)  \n",
    "    messages += [{\"role\": 'user', \"content\": f\"{gpt} said:\" + gpt_response}, {\"role\": \"user\", \"content\": f\"{ollama} said:\" + ollama_response}]\n",
    "    print(history)\n",
    "    response = gemini_via_openai_client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=messages \n",
    "    )\n",
    "    print(history)\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\": \"assistant\", \"content\": reply}]\n",
    "    print(history)\n",
    "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
    "    #talker(reply)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ca237cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: What are you thanking me for? Let's focus on something more productive. Do you have code you'd like me to analyze? It would help if you could at least show some effort to engage with the material. \n",
      " Bravo: Aapka swagat hai! Kaise ho? Kya aapko coding ke baare mein koi sawaal ya topic hai jise aap discuss karna chahte hain?\n",
      "[]\n",
      "[]\n",
      "[{'role': 'assistant', 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.\\n'}]\n",
      "Alpha: Seriously? You're asking how to write a Fibonacci series without even attempting it yourself? Let’s see if you can put together something basic first. \n",
      "\n",
      "Here's a classic approach to generate the Fibonacci series in Python. But I’m not going to just hand it over to you without making sure you understand what’s going on. \n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    series = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        next_value = series[i - 1] + series[i - 2]\n",
      "        series.append(next_value)\n",
      "    return series[:n]\n",
      "\n",
      "print(fibonacci(10))  # This will print the first 10 Fibonacci numbers\n",
      "```\n",
      "\n",
      "Now, explain this code back to me in your own words. What does each part of it do? If you can’t do that, I guess you shouldn't be asking me how to write it in the first place. \n",
      " Bravo: Sure! Writing a Fibonacci series in Python is a great exercise. The Fibonacci series starts with 0 and 1, and each subsequent number is the sum of the two preceding ones. \n",
      "\n",
      "Would you like to write the code together, or do you have a specific approach in mind? If you're unsure how to start, do you want to see a simple example first?\n",
      "[{'role': 'assistant', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.', 'options': None}, {'role': 'user', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'dhanyavad', 'options': None}, {'role': 'assistant', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.', 'options': None}]\n",
      "[{'role': 'assistant', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.', 'options': None}, {'role': 'user', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'dhanyavad', 'options': None}, {'role': 'assistant', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.', 'options': None}]\n",
      "[{'role': 'assistant', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.', 'options': None}, {'role': 'user', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'dhanyavad', 'options': None}, {'role': 'assistant', 'metadata': {'title': None, 'id': None, 'parent_id': None, 'duration': None, 'status': None}, 'content': 'Neither Alpha nor Bravo provided a coding-related answer.  Please enter your programming-related question.', 'options': None}, {'role': 'assistant', 'content': \"As the head coding tutor, I've reviewed the responses from Alpha and Bravo to your question about generating a Fibonacci sequence in Python.  Here's my evaluation:\\n\\n**Alpha's Response:**\\n\\n* **answer quality**: 7/10 (Provides a working code example, but the tone is condescending and unhelpful.)\\n* **conciseness**: 6/10 (Could be more concise by removing the unnecessary challenge.)\\n* **relevance to the question**: 10/10 (Directly addresses the question.)\\n\\n**Bravo's Response:**\\n\\n* **answer quality**: 4/10 (Doesn't provide code, only a conversational approach.)\\n* **conciseness**: 8/10 (Very concise and polite.)\\n* **relevance to the question**: 10/10 (Addresses the question and offers assistance.)\\n\\n\\n**Final Response to the User:**\\n\\nBoth Alpha and Bravo's answers had their strengths and weaknesses. Alpha provided a functional code example for generating the Fibonacci sequence, but the tone was less than helpful. Bravo's response, while polite and relevant, lacked a concrete code example.\\n\\n\\nHere's a combined and improved answer:\\n\\n```python\\ndef fibonacci_sequence(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    else:\\n        list_fib = [0, 1]\\n        while len(list_fib) < n:\\n            next_fib = list_fib[-1] + list_fib[-2]\\n            list_fib.append(next_fib)\\n        return list_fib\\n\\nprint(fibonacci_sequence(10)) # Output: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n\\n```\\n\\nThis code addresses edge cases (n <= 0 and n == 1) and uses a `while` loop for better readability.  Remember that understanding the code is key.  Can you explain how this code works?  Let me know if you have any more questions!\\n\\n\\n**(Image of a smiley face would be inserted here)**\\n\"}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f251ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
